{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from grapycal_audio_torch.dataset import PianoRollDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grapycal_audio.pianoroll import PianoRoll\n",
    "\n",
    "def tokenize(pr:PianoRoll, n_velocity=128, duration:int|None=None, seq_len:int|None=None):\n",
    "    tokens = []\n",
    "    frame = 0\n",
    "    if duration is None:\n",
    "        duration = pr.duration\n",
    "\n",
    "    tokens.append({'type':'start', 'frame':frame})\n",
    "    for note in pr.notes:\n",
    "        if note.onset > duration:\n",
    "            break\n",
    "        while note.onset > frame:\n",
    "            tokens.append({'type':'next_frame', 'frame':frame})\n",
    "            frame += 1\n",
    "        \n",
    "        tokens.append({'type':'pitch', 'frame':frame, 'value':note.pitch-21})\n",
    "        tokens.append({'type':'velocity', 'frame':frame, 'value':int(note.velocity*(n_velocity/128))})\n",
    "\n",
    "    while duration > frame:\n",
    "        tokens.append({'type':'next_frame', 'frame':frame})\n",
    "        frame += 1\n",
    "\n",
    "    # fill in the next_frame\n",
    "    for i in range(len(tokens)-1):\n",
    "        tokens[i]['next_frame'] = tokens[i+1]['frame']\n",
    "\n",
    "    tokens.pop() # remove the last next_frame 128\n",
    "\n",
    "    # we're using seq_len+1 because start token doesn't count\n",
    "    if seq_len is not None:\n",
    "        tokens = tokens[:seq_len+1]\n",
    "\n",
    "        if len(tokens) < seq_len+1:\n",
    "            tokens += [{'type':'pad'}] * (seq_len+1 - len(tokens))\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_positional_encoding(length:int, dim:int):\n",
    "    res = []\n",
    "    for i in range(length):\n",
    "        res.append([int(x) for x in f\"{i:0{dim}b}\"])\n",
    "        # pad\n",
    "        res[-1] += [0] * (dim - len(res[-1])) \n",
    "\n",
    "    return (\n",
    "        torch.tensor(res, dtype=torch.float32)\n",
    "    )\n",
    "    \n",
    "def sinusoidal_positional_encoding(length:int, dim:int):\n",
    "    res = []\n",
    "    for d in range(dim // 2):\n",
    "        res.append(torch.sin(torch.arange(length) / 10000 ** (2 * d / dim)))\n",
    "    for d in range(dim // 2):\n",
    "        res.append(torch.cos(torch.arange(length) / 10000 ** (2 * d / dim)))\n",
    "    return torch.stack(res, dim=1)\n",
    "\n",
    "def construct_input_frame(token:dict, pos_encoding:torch.Tensor, n_pitch, n_velocity, frame_bias:int = 0):\n",
    "\n",
    "    if token['type'] == 'pad':\n",
    "        return torch.zeros(n_pitch + n_velocity + 2 + pos_encoding.shape[1] * 2 )\n",
    "\n",
    "    #pitch\n",
    "    pitch = torch.zeros(n_pitch)\n",
    "    if token['type'] == 'pitch':\n",
    "        pitch[token['value']] = 1\n",
    "\n",
    "    #velocity\n",
    "    velocity = torch.zeros(n_velocity)\n",
    "    if token['type'] == 'velocity':\n",
    "        velocity[token['value']] = 1\n",
    "\n",
    "    #next_frame\n",
    "    next_frame = torch.zeros(1)\n",
    "    if token['type'] == 'next_frame':\n",
    "        next_frame[0] = 1\n",
    "    \n",
    "    #start\n",
    "    start = torch.zeros(1)\n",
    "    if token['type'] == 'start':\n",
    "        start[0] = 1\n",
    "\n",
    "    #pos\n",
    "    pos = pos_encoding[token['frame']-frame_bias]\n",
    "\n",
    "    #target pos\n",
    "    target_pos = pos_encoding[token['next_frame']-frame_bias]\n",
    "    \n",
    "\n",
    "    return torch.cat([pitch, velocity, next_frame, start, pos, target_pos], dim=0)\n",
    "\n",
    "def construct_input_tensor(tokens, pos_encoding:torch.Tensor, n_pitch, n_velocity, frame_bias:int = 0):\n",
    "\n",
    "    frame_axis = []\n",
    "\n",
    "    for token in tokens:\n",
    "        frame_axis.append(construct_input_frame(token, pos_encoding, n_pitch, n_velocity, frame_bias=frame_bias))\n",
    "\n",
    "    return torch.stack(frame_axis, dim=0)\n",
    "\n",
    "def construct_output_mask(tokens, n_pitch, n_velocity):\n",
    "    '''\n",
    "    An additive mask for the model's output (logits) to prevent the model from predicting invalid tokens.\n",
    "\n",
    "    The first token must be pitch or next_frame.\n",
    "    The next token of pitch must be velocity.\n",
    "    The next token of next_frame can be pitch or next_frame.\n",
    "    The next token of velocity must be pitch or next_frame.\n",
    "\n",
    "    Accroding to the above rule, we can construct a mask as a prior on the model's prediction.\n",
    "    '''\n",
    "\n",
    "    mask = torch.zeros(len(tokens), n_pitch + n_velocity + 1)\n",
    "    # fill with -inf\n",
    "    mask = mask - 1e7\n",
    "\n",
    "    mask[0, :n_pitch] = 0\n",
    "    mask[0, n_pitch+n_velocity] = 0\n",
    "\n",
    "    for i in range(len(tokens)-1):\n",
    "        # output shape: Output: [pitch(n_pitch), velocity(n_velocity), next_frame(1)]\n",
    "        token = tokens[i]\n",
    "\n",
    "        if token['type'] == 'pitch':\n",
    "            #enable velocity\n",
    "            mask[i+1, n_pitch:n_pitch+n_velocity] = 0\n",
    "        if token['type'] == 'velocity':\n",
    "            #enable pitch or next_frame\n",
    "            mask[i+1, :n_pitch] = 0\n",
    "            mask[i+1, n_pitch+n_velocity] = 0\n",
    "        if token['type'] == 'next_frame':\n",
    "            #enable pitch or next_frame\n",
    "            mask[i+1, :n_pitch] = 0\n",
    "            mask[i+1, n_pitch+n_velocity] = 0\n",
    "\n",
    "    return mask\n",
    "\n",
    "def construct_target(tokens, n_pitch, n_velocity):\n",
    "    res = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token['type'] == 'pitch':\n",
    "            res.append(token['value'])\n",
    "        elif token['type'] == 'velocity':\n",
    "            res.append(n_pitch + token['value'])\n",
    "        elif token['type'] == 'next_frame':\n",
    "            res.append(n_pitch + n_velocity)\n",
    "        elif token['type'] == 'pad':\n",
    "            res.append(-100) # -100 is the ignore index\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown token type: {token['type']}\")\n",
    "\n",
    "    return torch.tensor(res, dtype=torch.long)\n",
    "\n",
    "pos_encoding = torch.cat([\n",
    "    binary_positional_encoding(512,9),\n",
    "    sinusoidal_positional_encoding(512, 31)\n",
    "], dim=1)\n",
    "\n",
    "class TokenizedPianoRollDataset(Dataset):\n",
    "    '''\n",
    "    Input: [pitch(n_pitch), velocity(n_velocity), next_frame(1), start(1), pos, target_pos]\n",
    "    Output: [pitch(n_pitch), velocity(n_velocity), next_frame(1)]\n",
    "    '''\n",
    "    def __init__(self, path:str, pos_encoding:torch.Tensor, segment_length:int, hop_len:int, seq_len:int, n_pitch:int, n_velocity:int):\n",
    "        self.ds = PianoRollDataset(path, segment_len=segment_length, hop_len=hop_len)\n",
    "        self.pos_encoding = pos_encoding\n",
    "        self.seq_len = seq_len\n",
    "        self.n_pitch = n_pitch\n",
    "        self.n_velocity = n_velocity\n",
    "        self.segment_length = segment_length\n",
    "\n",
    "        #self.tokens = []\n",
    "        #for idx in range(len(self.ds)):\n",
    "        #    self.tokens.append(tokenize(self.ds.get_piano_roll(idx), n_velocity=self.n_velocity, duration=self.segment_length, seq_len=self.seq_len))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #tokens = self.tokens[idx]\n",
    "\n",
    "        pr = self.ds.get_piano_roll(idx)\n",
    "        tokens = tokenize(pr, n_velocity=self.n_velocity, duration=self.segment_length, seq_len=self.seq_len)\n",
    "\n",
    "        tokens_without_start = tokens[1:]\n",
    "\n",
    "        # the last token is not needed to be an input\n",
    "        input = construct_input_tensor(tokens[:-1], pos_encoding=self.pos_encoding, n_pitch=self.n_pitch, n_velocity=self.n_velocity)\n",
    "        target = construct_target(tokens_without_start, n_pitch=self.n_pitch, n_velocity=self.n_velocity)\n",
    "        output_mask = construct_output_mask(tokens_without_start, n_pitch=self.n_pitch, n_velocity=self.n_velocity)\n",
    "        return {'input':input, 'target':target, 'output_mask':output_mask}\n",
    "    \n",
    "    def get_loss_weight(self):\n",
    "        '''\n",
    "        The loss weight for each token.\n",
    "        '''\n",
    "        res = torch.ones(self.n_pitch + self.n_velocity + 1)\n",
    "        res[self.n_pitch + self.n_velocity] = 0.05 # next_frame is too common so we need to reduce its weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset segment_len = 512\n",
      "Created dataset with 17141 data points from 2570 pieces\n"
     ]
    }
   ],
   "source": [
    "ds = TokenizedPianoRollDataset('../dev_cwd/_data/gr_resource/download/music/pop_piano', pos_encoding, 512, 512, 1400, 88, 32)\n",
    "dl = DataLoader(ds,batch_size=8, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/gr/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "# input: B, 350, 202\n",
    "# output: B, 350, 121\n",
    "\n",
    "class PianoRollGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_linear = nn.Linear(200, 256)\n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=256, nhead=8, dim_feedforward=1024, batch_first=True), num_layers=6)\n",
    "        self.out_linear = nn.Linear(256, 121)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_linear(x)\n",
    "        x = self.transformer(x, mask = nn.Transformer.generate_square_subsequent_mask(x.shape[1]).to(x.device), is_causal = True)\n",
    "        x = self.out_linear(x)\n",
    "        return x\n",
    "        \n",
    "model = PianoRollGenerator()\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "opt = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from grapycal_audio.pianoroll import Note\n",
    "\n",
    "def top_k(logits:torch.Tensor, k):\n",
    "    values, indices = logits.topk(k)\n",
    "    probs = torch.softmax(values, dim=0)\n",
    "    selected = torch.multinomial(probs, 1)\n",
    "    return indices[selected]\n",
    "\n",
    "def decode(logits, last_token, n_pitch, n_velocity):\n",
    "    frame = last_token['next_frame']\n",
    "\n",
    "    if last_token['type'] in ['start', 'velocity', 'next_frame']:\n",
    "        logits[n_pitch:n_pitch+n_velocity] = - torch.inf\n",
    "        max_idx = top_k(logits, 15).item()\n",
    "        if max_idx < n_pitch:\n",
    "            return {'type':'pitch', 'value':max_idx, 'frame':frame, 'next_frame':frame}\n",
    "        elif max_idx == n_pitch + n_velocity:\n",
    "            return {'type':'next_frame', 'frame':frame, 'next_frame':frame+1}\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid index: {max_idx}\")\n",
    "        \n",
    "    elif last_token['type'] == 'pitch':\n",
    "        logits[:n_pitch] = -torch.inf\n",
    "        logits[n_pitch+n_velocity] = -torch.inf\n",
    "        max_idx = top_k(logits, 15).item()\n",
    "        return {'type':'velocity', 'value':max_idx - n_pitch, 'frame':frame, 'next_frame':frame}\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown token type: {last_token['type']}\")\n",
    "    \n",
    "def token_to_pianoroll(tokens):\n",
    "    notes = []\n",
    "    frame = 0\n",
    "    last_pitch = None\n",
    "    for token in tokens:\n",
    "        if token['type'] == 'start':\n",
    "            continue\n",
    "        if token['type'] == 'pitch':\n",
    "            last_pitch = token['value']\n",
    "        if token['type'] == 'velocity':\n",
    "            notes.append(Note(onset=frame, pitch=last_pitch+21, velocity=int(token['value']*(128/32))))\n",
    "        if token['type'] == 'next_frame':\n",
    "            frame += 1\n",
    "    return PianoRoll(notes)\n",
    "    \n",
    "# logits = out[0].detach().cpu()\n",
    "\n",
    "# n_pitch = 88\n",
    "# n_velocity = 32\n",
    "# last_token = {'type':'start', 'frame':0, 'next_frame':0}\n",
    "# tokens = []\n",
    "# for frame_logits in logits:\n",
    "#     decoded = decode(frame_logits, last_token, n_pitch, n_velocity)\n",
    "#     tokens.append(decoded)\n",
    "#     last_token = decoded\n",
    "def inference(file_path:str, max_duration:int, max_length:int, prompt: list[dict]|None=None):\n",
    "    model.eval()\n",
    "    n_pitch = 88\n",
    "    n_velocity = 32\n",
    "    if prompt is None:\n",
    "        tokens = [{'type':'start', 'frame':0, 'next_frame':0}]\n",
    "    else:\n",
    "        tokens = prompt\n",
    "    \n",
    "    while tokens[-1]['next_frame'] < max_duration and len(tokens) < max_length:\n",
    "        input = construct_input_tensor(tokens, pos_encoding=pos_encoding, n_pitch=n_pitch, n_velocity=n_velocity).unsqueeze(0)\n",
    "        input = input.to(device)\n",
    "        logits = model(input).squeeze(0)[-1].detach().cpu()\n",
    "        decoded = decode(logits, tokens[-1], n_pitch, n_velocity)\n",
    "        tokens.append(decoded)\n",
    "\n",
    "    token_to_pianoroll(tokens).to_midi(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2143/2143 [01:48<00:00, 19.79it/s, batch=2100, gpu_temp=0, loss=0.846]\n",
      "100%|██████████| 2143/2143 [01:40<00:00, 21.22it/s, batch=2100, gpu_temp=0, loss=1.11] \n",
      "100%|██████████| 2143/2143 [01:41<00:00, 21.16it/s, batch=2100, gpu_temp=0, loss=1.16] \n",
      "100%|██████████| 2143/2143 [01:42<00:00, 20.89it/s, batch=2100, gpu_temp=0, loss=0.966]\n",
      "100%|██████████| 2143/2143 [01:42<00:00, 21.01it/s, batch=2100, gpu_temp=0, loss=1.05] \n",
      "100%|██████████| 2143/2143 [01:41<00:00, 21.21it/s, batch=2100, gpu_temp=0, loss=1.1]  \n",
      "100%|██████████| 2143/2143 [01:41<00:00, 21.10it/s, batch=2100, gpu_temp=0, loss=0.848]\n",
      "100%|██████████| 2143/2143 [01:40<00:00, 21.29it/s, batch=2100, gpu_temp=0, loss=1.21] \n",
      "100%|██████████| 2143/2143 [01:41<00:00, 21.16it/s, batch=2100, gpu_temp=0, loss=0.909]\n",
      "100%|██████████| 2143/2143 [01:41<00:00, 21.10it/s, batch=2100, gpu_temp=0, loss=0.997]\n",
      "100%|██████████| 2143/2143 [01:41<00:00, 21.13it/s, batch=2100, gpu_temp=0, loss=0.927]\n",
      "100%|██████████| 2143/2143 [01:41<00:00, 21.15it/s, batch=2100, gpu_temp=0, loss=0.889]\n",
      "100%|██████████| 2143/2143 [01:38<00:00, 21.72it/s, batch=2100, gpu_temp=0, loss=1.09] \n",
      "100%|██████████| 2143/2143 [01:37<00:00, 21.93it/s, batch=2100, gpu_temp=0, loss=0.783]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.23it/s, batch=2100, gpu_temp=0, loss=0.842]\n",
      "100%|██████████| 2143/2143 [01:37<00:00, 22.05it/s, batch=2100, gpu_temp=0, loss=0.895]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.26it/s, batch=2100, gpu_temp=0, loss=0.925]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.14it/s, batch=2100, gpu_temp=0, loss=0.848]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.26it/s, batch=2100, gpu_temp=0, loss=0.909]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.10it/s, batch=2100, gpu_temp=0, loss=0.83] \n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.23it/s, batch=2100, gpu_temp=0, loss=0.775]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.13it/s, batch=2100, gpu_temp=0, loss=0.672]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.26it/s, batch=2100, gpu_temp=0, loss=0.994]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.20it/s, batch=2100, gpu_temp=0, loss=0.978]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.22it/s, batch=2100, gpu_temp=0, loss=0.909]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.20it/s, batch=2100, gpu_temp=0, loss=0.912]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.15it/s, batch=2100, gpu_temp=0, loss=0.711]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.18it/s, batch=2100, gpu_temp=0, loss=0.676]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.18it/s, batch=2100, gpu_temp=0, loss=1.09] \n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.32it/s, batch=2100, gpu_temp=0, loss=0.861]\n",
      "100%|██████████| 2143/2143 [01:36<00:00, 22.22it/s, batch=2100, gpu_temp=0, loss=0.86] \n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.67it/s, batch=2100, gpu_temp=0, loss=1.01] \n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.66it/s, batch=2100, gpu_temp=0, loss=0.824]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.65it/s, batch=2100, gpu_temp=0, loss=0.869]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.68it/s, batch=2100, gpu_temp=0, loss=0.842]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.66it/s, batch=2100, gpu_temp=0, loss=0.855]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.71it/s, batch=2100, gpu_temp=0, loss=0.926]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.70it/s, batch=2100, gpu_temp=0, loss=1.02] \n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.69it/s, batch=2100, gpu_temp=0, loss=0.987]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.69it/s, batch=2100, gpu_temp=0, loss=0.782]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.71it/s, batch=2100, gpu_temp=0, loss=0.834]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.69it/s, batch=2100, gpu_temp=0, loss=0.821]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.66it/s, batch=2100, gpu_temp=0, loss=0.841]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.64it/s, batch=2100, gpu_temp=0, loss=0.806]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.65it/s, batch=2100, gpu_temp=0, loss=0.953]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.73it/s, batch=2100, gpu_temp=0, loss=0.709]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.72it/s, batch=2100, gpu_temp=0, loss=0.805]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.73it/s, batch=2100, gpu_temp=0, loss=0.959]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.71it/s, batch=2100, gpu_temp=0, loss=0.79] \n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.73it/s, batch=2100, gpu_temp=0, loss=0.769]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.71it/s, batch=2100, gpu_temp=0, loss=0.901]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.68it/s, batch=2100, gpu_temp=0, loss=0.571]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.69it/s, batch=2100, gpu_temp=0, loss=0.904]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.70it/s, batch=2100, gpu_temp=0, loss=0.863]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.67it/s, batch=2100, gpu_temp=0, loss=0.806]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.66it/s, batch=2100, gpu_temp=0, loss=0.768]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.73it/s, batch=2100, gpu_temp=0, loss=1]    \n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.70it/s, batch=2100, gpu_temp=0, loss=0.933]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.70it/s, batch=2100, gpu_temp=0, loss=0.844]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.66it/s, batch=2100, gpu_temp=0, loss=0.892]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.66it/s, batch=2100, gpu_temp=0, loss=0.883]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.64it/s, batch=2100, gpu_temp=0, loss=0.829]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.59it/s, batch=2100, gpu_temp=0, loss=0.894]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.73it/s, batch=2100, gpu_temp=0, loss=0.757]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.82it/s, batch=2100, gpu_temp=0, loss=0.736]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.80it/s, batch=2100, gpu_temp=0, loss=0.834]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.84it/s, batch=2100, gpu_temp=0, loss=0.761]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.80it/s, batch=2100, gpu_temp=0, loss=0.728]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.84it/s, batch=2100, gpu_temp=0, loss=0.789]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.81it/s, batch=2100, gpu_temp=0, loss=0.575]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.83it/s, batch=2100, gpu_temp=0, loss=0.719]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.82it/s, batch=2100, gpu_temp=0, loss=0.963]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.81it/s, batch=2100, gpu_temp=0, loss=0.671]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.87it/s, batch=2100, gpu_temp=0, loss=0.738]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.76it/s, batch=2100, gpu_temp=0, loss=0.749]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.84it/s, batch=2100, gpu_temp=0, loss=0.667]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.80it/s, batch=2100, gpu_temp=0, loss=0.896]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.86it/s, batch=2100, gpu_temp=0, loss=0.744]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.79it/s, batch=2100, gpu_temp=0, loss=0.977]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.82it/s, batch=2100, gpu_temp=0, loss=0.742]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.79it/s, batch=2100, gpu_temp=0, loss=0.925]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.79it/s, batch=2100, gpu_temp=0, loss=0.992]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.86it/s, batch=2100, gpu_temp=0, loss=0.94] \n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.84it/s, batch=2100, gpu_temp=0, loss=0.694]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.83it/s, batch=2100, gpu_temp=0, loss=0.695]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.84it/s, batch=2100, gpu_temp=0, loss=0.808]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.82it/s, batch=2100, gpu_temp=0, loss=0.665]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.81it/s, batch=2100, gpu_temp=0, loss=0.711]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.79it/s, batch=2100, gpu_temp=0, loss=0.856]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.83it/s, batch=2100, gpu_temp=0, loss=0.835]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.77it/s, batch=2100, gpu_temp=0, loss=0.667]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.82it/s, batch=2100, gpu_temp=0, loss=0.655]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.82it/s, batch=2100, gpu_temp=0, loss=0.781]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.83it/s, batch=2100, gpu_temp=0, loss=0.808]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.79it/s, batch=2100, gpu_temp=0, loss=0.71] \n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.83it/s, batch=2100, gpu_temp=0, loss=0.979]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.83it/s, batch=2100, gpu_temp=0, loss=0.622]\n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.83it/s, batch=2100, gpu_temp=0, loss=0.59] \n",
      "100%|██████████| 2143/2143 [01:33<00:00, 22.85it/s, batch=2100, gpu_temp=0, loss=0.871]\n",
      "100%|██████████| 2143/2143 [01:34<00:00, 22.78it/s, batch=2100, gpu_temp=0, loss=0.836]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "crit.to(device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    tq = tqdm(dl)\n",
    "    for i, batch in enumerate(tq):\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        opt.zero_grad()\n",
    "        out = model(batch['input'])\n",
    "        loss = crit((out+batch['output_mask']).transpose(1,2), batch['target'])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if i % 100 == 0:\n",
    "            # print the loss to tqdm\n",
    "            #temp = torch.cuda.temperature()\n",
    "            temp = 0\n",
    "            tq.set_postfix(batch = i, loss= loss.item(), gpu_temp=temp)\n",
    "\n",
    "            if temp > 65:\n",
    "                print(\"GPU temperature is too high. Slowin down.\", temp)\n",
    "                time.sleep(0.1)\n",
    "        \n",
    "                    \n",
    "        if torch.isnan(loss):\n",
    "            raise ValueError(\"Loss is NaN\")\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        inference(f'./output_{epoch}_{i}.mid')\n",
    "        torch.save(model.state_dict(), f'./model_{epoch}.pth')\n",
    "        torch.save(opt.state_dict(), f'./opt_{epoch}.pth')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 512 is out of bounds for dimension 0 with size 512",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfree2108252.mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPianoRoll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_midi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfree210825_2_C.mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_velocity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[46], line 75\u001b[0m, in \u001b[0;36minference\u001b[0;34m(file_path, prompt)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# add the token to the list and the input tensor\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     tokens\u001b[38;5;241m.\u001b[39mappend(decoded)\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28minput\u001b[39m, \u001b[43mconstruct_input_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_pitch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_pitch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_velocity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_velocity\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     77\u001b[0m token_to_pianoroll(tokens)\u001b[38;5;241m.\u001b[39mto_midi(file_path)\n",
      "Cell \u001b[0;32mIn[3], line 59\u001b[0m, in \u001b[0;36mconstruct_input_tensor\u001b[0;34m(tokens, pos_encoding, n_pitch, n_velocity)\u001b[0m\n\u001b[1;32m     56\u001b[0m frame_axis \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[0;32m---> 59\u001b[0m     frame_axis\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconstruct_input_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_pitch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_velocity\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(frame_axis, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 49\u001b[0m, in \u001b[0;36mconstruct_input_frame\u001b[0;34m(token, pos_encoding, n_pitch, n_velocity)\u001b[0m\n\u001b[1;32m     46\u001b[0m pos \u001b[38;5;241m=\u001b[39m pos_encoding[token[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#target pos\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m target_pos \u001b[38;5;241m=\u001b[39m \u001b[43mpos_encoding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnext_frame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([pitch, velocity, next_frame, start, pos, target_pos], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 512 is out of bounds for dimension 0 with size 512"
     ]
    }
   ],
   "source": [
    "inference('free2108252.mid',tokenize(PianoRoll.from_midi('free210825_2_C.mid').random_slice(128), n_velocity=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'next_frame', 'frame': 78, 'next_frame': 79}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference('free2108252.mid',tokenize(PianoRoll.from_midi('free210825_2_C.mid').random_slice(128), n_velocity=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4821113"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'velocity', 'frame': 116, 'value': 14, 'next_frame': 116},\n",
       " {'type': 'pitch', 'frame': 116, 'value': 48, 'next_frame': 116},\n",
       " {'type': 'velocity', 'frame': 116, 'value': 23, 'next_frame': 116},\n",
       " {'type': 'next_frame', 'frame': 116, 'next_frame': 117},\n",
       " {'type': 'next_frame', 'frame': 117, 'next_frame': 118},\n",
       " {'type': 'next_frame', 'frame': 118, 'next_frame': 119},\n",
       " {'type': 'next_frame', 'frame': 119, 'next_frame': 120},\n",
       " {'type': 'pitch', 'frame': 120, 'value': 38, 'next_frame': 120},\n",
       " {'type': 'velocity', 'frame': 120, 'value': 22, 'next_frame': 120},\n",
       " {'type': 'next_frame', 'frame': 120, 'next_frame': 121},\n",
       " {'type': 'next_frame', 'frame': 121, 'next_frame': 122},\n",
       " {'type': 'next_frame', 'frame': 122, 'next_frame': 123},\n",
       " {'type': 'next_frame', 'frame': 123, 'next_frame': 124},\n",
       " {'type': 'pitch', 'frame': 124, 'value': 29, 'next_frame': 124},\n",
       " {'type': 'velocity', 'frame': 124, 'value': 20, 'next_frame': 124},\n",
       " {'type': 'pitch', 'frame': 124, 'value': 50, 'next_frame': 124},\n",
       " {'type': 'velocity', 'frame': 124, 'value': 21, 'next_frame': 124},\n",
       " {'type': 'next_frame', 'frame': 124, 'next_frame': 125},\n",
       " {'type': 'next_frame', 'frame': 125, 'next_frame': 126},\n",
       " {'type': 'next_frame', 'frame': 126, 'next_frame': 127}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(PianoRoll.from_midi('free210825_2_C.mid').random_slice(128), n_velocity=32)[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4])\n",
      "tensor([ 2, 36])\n",
      "tensor([5, 1])\n",
      "tensor([3, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "ds = [1,2,3,4,5,36,4,1]\n",
    "dl = DataLoader(ds, batch_size=2, shuffle=True, num_workers=2)\n",
    "for b in dl:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "quality = {\n",
    "    '': [0,4,7],\n",
    "    'm': [0,3,7],\n",
    "    '7': [0,4,7,10],\n",
    "    'm7': [0,3,7,10],\n",
    "}\n",
    "chord_to_chroma = {}\n",
    "for i, s in enumerate(scale):\n",
    "    for q in quality:\n",
    "        chord_to_chroma[f\"{s}{q}\"] = [(x+i)%12 for x in quality[q]]\n",
    "\n",
    "def chroma_to_chord(query):\n",
    "    scores = {}\n",
    "    for chord, chroma in chord_to_chroma.items():\n",
    "        score = 0\n",
    "        for i in chroma:\n",
    "            score += query[i]\n",
    "        scores[chord] = score\n",
    "    print(scores)\n",
    "    argmax = max(scores, key=scores.get)\n",
    "    return argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3333333333333335,\n",
       " 1.0,\n",
       " 3.3333333333333335,\n",
       " 1.6666666666666667,\n",
       " 2.3333333333333335,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.3333333333333333,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.3333333333333333,\n",
       " 1.3333333333333333,\n",
       " 1.6666666666666667]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.ds.get_piano_roll(4884).get_polyphony()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticks per beat: 480\n",
       "max tick: 0\n",
       "tempo changes: 1\n",
       "time sig: 0\n",
       "key sig: 0\n",
       "markers: 0\n",
       "lyrics: False\n",
       "instruments: 1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.ds.get_piano_roll(4884).to_midi('test.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_n(array, n):\n",
    "    \"\"\"\n",
    "    Get the indices of the n largest elements in an array\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        if i >= len(array):\n",
    "            break\n",
    "        max_index = np.argmax(array)\n",
    "        result.append(max_index)\n",
    "        array[max_index] = 0\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_max_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m, in \u001b[0;36mget_max_n\u001b[0;34m(array, n)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(array):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m max_index \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39margmax(array)\n\u001b[1;32m     10\u001b[0m result\u001b[38;5;241m.\u001b[39mappend(max_index)\n\u001b[1;32m     11\u001b[0m array[max_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "get_max_n([1,2,3,4,5,6,7,8,9,10], 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
